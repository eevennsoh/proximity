
baseEndpoint: https://ai-gateway.us-east-1.staging.atl-paas.net

supportedUris:

  # ******* OPENAI ******* #

  - in: /openai/v1/chat/completions
    out: /v1/openai/v1/chat/completions

  - in: /openai/v1/responses
    out: /v1/openai/v1/responses

  - in: /openai/v1/models

  # ******* CLAUDE ******* #

  - in: /bedrock/claude/v1/messages
    out: |
      /v1/bedrock/model/{{ trim .body.model "anthropic." "-v1:0" }}/invoke{{- if .body.stream -}}-with-response-stream{{- end -}}

  - in: /bedrock/claude/v1/models

  # Claude Code direct model invocation endpoints
  - in: /bedrock/claude/v1/model/{model}/invoke
    out: /v1/bedrock/model/{{ .pathParams.model }}/invoke

  - in: /bedrock/claude/v1/model/{model}/invoke-with-response-stream
    out: /v1/bedrock/model/{{ .pathParams.model }}/invoke-with-response-stream

  - in: /provider/bedrock/format/openai/v1/chat/completions
    out: |
      /v1/bedrock/model/{{ trim .body.model "anthropic." "-v1:0" }}/invoke{{- if .body.stream -}}-with-response-stream{{- end -}}

  - in: /provider/bedrock/format/openai/v1/models

  # ******* GEMINI ******* #

  - in: /google/gemini/v1beta/models/{model}:generateContent
    out: /v1/google/v1/publishers/google/models/{{ .pathParams.model }}:generateContent

  - in: /google/gemini/v1beta/models/{model}:streamGenerateContent
    out: /v1/google/v1/publishers/google/models/{{ .pathParams.model }}:streamGenerateContent

overrides:
  global:
    request:
      headers:
        # If no name is define for op: remove, then it removes all headers
        - op: remove

        - op: add
          name: Content-Type
          text: application/json
        - op: add
          name: Accept
          text: application/json
        - op: add
          name: X-Atlassian-CloudId
          text: a436116f-02ce-4520-8fbb-7301462a1674
        - op: add
          name: X-Atlassian-UseCaseId
          text: autofix-service-internal
        - op: add
          name: Authorization
          text: 'slauth {{ slauthtoken "atlassian-all" "ai-gateway" "staging" }}'

      response:
        headers: []

  uris:
    # Generate the entire response to mimick an upstream OpenAI endpoint. This
    # is done because AI-Gateway does not provide this endpoint.
    /openai/v1/models:
      response:
        headers:
          - op: add
            name: Content-Type
            text: application/json

        body:
          template: |
            {
              "object": "list",
              "data": [
                {{- $first := true }}
                {{- range $model := .external.openai }}
                {{- if not $first }},{{ end }}
                {{- $first = false }}
                {
                  "id": "{{ $model }}",
                  "object": "model",
                  "created": {{ timestamp }},
                  "owned_by": "atlassian"
                }
                {{- end }}
              ]
            }

    # Use the Bedrock provider. All models can be accessed through the proxy
    # using the anthropic claude format.
    /bedrock/claude/v1/messages:
      request:
        headers:
          # The bedrock api requires the anthropic version in the body rather
          # than as a header like the anthropic api so the header needs to be
          # removed.
          - op: remove
            name: anthropic-version

          # No need for this when using AI-Gateway
          - op: remove
            name: x-api-key
        body:
          template: |
            {
              {{- $first := true }}
              {{- range $k, $v := .body }}
              {{- if and (ne $k "model") (ne $k "stream") (ne $k "messages") }}
                {{- if not $first }},{{ end }}
                "{{ $k }}": {{ toJson $v }}
                {{- $first = false }}
              {{- end }}
              {{- end }},
              {{/* The bedrock api requires the anthropic version in the json body */}}
              "anthropic_version": "bedrock-2023-05-31",
              "messages": [
                {{- $firstMsg := true }}
                {{- range $msg := .body.messages }}
                  {{- if not $firstMsg }},{{ end }}
                  {{- $firstMsg = false }}
                  {{- if eq (getType $msg.content) "string" }}
                    {
                      "role": "{{ $msg.role }}",
                      "content": [
                        {
                          "type": "text",
                          "text": "{{ safeEncode $msg.content }}"
                        }
                      ]
                    }
                  {{- else }}
                    {{ toJson $msg }}
                  {{- end }}
                {{- end }}
              ]
            }

      response:
        body:
          # TODO: add body response templating
          template: |
            {{- /* differentiate between whether the response is returned as an event stream or a full response */}}
            {{- if .event }}
              {{- if eq .event.type "message_stop" }}
                { "type": "message_stop" }
              {{- else if eq .event.type "message_start" }}
                {
                  "type": "message_start",
                  "usage": {
                    "input_tokens": {{ .event.message.usage.input_tokens }},
                    "output_tokens": {{ .event.message.usage.output_tokens }}
                  }
                }
              {{- else }}
                {{ toJson .event }}
              {{- end }}
            {{- end }}

    /bedrock/claude/v1/models:
      response:
        headers:
          - op: add
            name: Content-Type
            text: application/json

        body:
          template: |
            {
              "data": [
                {{- $first := true }}
                {{- range $model := .external.anthropic }}
                {{- if not $first }},{{ end }}
                {{- $first = false }}
                {
                  "created_at": "{{ formattedTimestamp "2006-01-02T15:04:05Z" }}",
                  "display_name": "{{ $model }}",
                  "id": "{{ $model }}",
                  "type": "model"
                }
                {{- end }}
              ],
              "first_id": "{{ index .external.anthropic 0 }}",
              "has_more": false,
              "last_id": "{{ index .external.anthropic (subtract (len .external.anthropic) 1) }}"
            }

    /provider/bedrock/format/openai/v1/chat/completions:
      request:
        body:
          template: |
            {
              "anthropic_version": "bedrock-2023-05-31",

              {{- /* set max tokens if max_tokens or max_completion_tokens are defined */}}
              {{- if .body.max_tokens }}
              "max_tokens": {{ .body.max_tokens }},
              {{- else if .body.max_completion_tokens }}
              "max_tokens": {{ .body.max_completion_tokens }},
              {{- else}}
              "max_tokens": 8192,
              {{- end }}

              {{- /* system prompt: first message with role == "system" */}}
              {{- range $i, $msg := .body.messages }}
                {{- if and (eq $msg.role "system") (eq $i 0) }}
                  "system": "{{ safeEncode $msg.content }}",
                {{- end }}
              {{- end }}

              {{- if .body.tools }}
              "tools": [
                {{- $firstTool := true }}
                {{- range $tool := .body.tools }}
                  {{- if eq $tool.type "function" }}
                    {{- if not $firstTool }},{{ end }}
                    {
                      "name": "{{ $tool.function.name }}",
                      "description": "{{ safeEncode $tool.function.description }}",
                      "input_schema": {{ toJson $tool.function.parameters }}
                    }
                    {{- $firstTool = false }}
                  {{- end }}
                {{- end }}
              ],
              {{- end }}

              {{- if .body.tool_choice }}
              "tool_choice": {
              {{- if eq (getType .body.tool_choice) "string" -}}
                {{- if eq .body.tool_choice "auto" }}
                  "type": "auto"
                {{- else }}
                  "type": "any"
                {{- end }}
              {{- else }}
                "type": "tool",
                "name": "{{ .body.tool_choice.function.name }}"
              {{- end }}
              },
              {{- end }}

              {{- if .body.temperature }}
              "temperature": {{ .body.temperature }},
              {{- end }}
              {{- if .body.top_p }}
              "top_p": {{ .body.top_p }},
              {{- end }}

              {{- if .body.stop }}
                {{- if eq (getType .body.stop) "string" }}
                  "stop_sequences": [ "{{ .body.stop }}" ]
                {{- else if eq (getType .body.stop) "slice" }}
                  "stop_sequences": {{ toJson .body.stop }}
                {{- end }}
              {{- end }}

              "messages": [
                {{- $firstMsg := true }}
                {{- range $msg := .body.messages }}
                  {{- if ne $msg.role "system" }}
                    {{- if not $firstMsg }},{{ end }}
                    {{- $firstMsg = false }}
                    {
                      "role": "{{ $msg.role }}",
                      {{- if eq (getType $msg.content) "string" }}
                      "content": [
                        {
                          "type": "text",
                          "text": "{{ safeEncode $msg.content }}"
                        }
                      ]
                      {{- else }}
                      "content": [
                        {{- $firstContentMsg := true }}
                        {{- range $contentMsg := $msg.content }}
                          {{- if not $firstContentMsg }},{{ end }}
                          {{- $firstContentMsg = false }}
                          {
                            "type": "{{ $contentMsg.type }}",
                            "{{ $contentMsg.type }}": "{{ safeEncode (index $contentMsg $contentMsg.type) }}"
                          }
                        {{- end }}
                      ]
                      {{- end }}
                    }
                  {{- end }}
                {{- end }}
              ]
            }

      response:
        body:
          template: |
            {{- if .event }}
              {
                "object": "chat.completion.chunk",
                "created": {{ timestamp }},
                "service_tier": "scale",
                "system_fingerprint": null,

              {{- if eq .event.type "message_start" }}

                {{ set "requestId" .event.message.id }}
                {{ set "model" .event.message.model }}
                {{ set "role" .event.message.role }}
                {{ set "input_tokens" .event.message.usage.input_tokens }}
                {{ set "output_tokens" .event.message.usage.output_tokens }}

                "id": "{{ .event.message.id }}",
                "model": "{{ .event.message.model }}",

                "choices": [
                  {
                    "index": 0,
                    "delta": {
                      "role": "assistant",
                      "content": ""
                    },
                    "logprobs": null,
                    "finish_reason": null
                  }
                ],
                "usage": null

              {{- else if or (eq .event.type "content_block_start") (eq .event.type "content_block_stop") (eq .event.type "message_delta") }}

                "id": "{{ get "requestId" }}",
                "model": "{{ get "model" }}",

                "choices": [
                  {
                    "index": 0,
                    "delta": {
                      "role": "assistant",
                      "content": ""
                    },
                    "logprobs": null,
                    "finish_reason": null
                  }
                ],
                "usage": null

              {{- else if eq .event.type "message_stop" }}

                "id": "{{ get "requestId" }}",
                "model": "{{ get "model" }}",

                "choices": [],
                "usage": {
                  "prompt_tokens": {{ get "input_tokens" }},
                  "completion_tokens": {{ get "output_tokens" }},
                  "total_tokens": {{ sum (get "input_tokens") (get "output_tokens") }},
                  "prompt_tokens_details": {
                      "cached_tokens": 0,
                      "audio_tokens": 0
                  },
                  "completion_tokens_details": {
                      "reasoning_tokens": 0,
                      "audio_tokens": 0,
                      "accepted_prediction_tokens": 0,
                      "rejected_prediction_tokens": 0
                  }
                }

              {{- else }}

                "id": "{{ get "requestId" }}",
                "model": "{{ get "model" }}",

                "choices": [
                  {
                    "index": 0,
                    "delta": {
                      "content": "{{ safeEncode .event.delta.text }}"
                    },
                    "logprobs": null,
                    "finish_reason": null
                  }
                ],
                "usage": null

              {{- end }}
              }
            {{- end }}

    /provider/bedrock/format/openai/v1/models:
      response:
        headers:
          - op: add
            name: Content-Type
            text: application/json

        body:
          template: |
            {
              "object": "list",
              "data": [
                {{- $first := true }}
                {{- range $model := .external.anthropic }}
                {{- if not $first }},{{ end }}
                {{- $first = false }}
                {
                  "id": "{{ $model }}",
                  "object": "model",
                  "created": {{ timestamp }},
                  "owned_by": "atlassian"
                }
                {{- end }}
              ]
            }
