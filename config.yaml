
baseEndpoint: |
  "https://ai-gateway.us-east-1." + get(settings, "aiGatewayEnv") ?? "staging" + ".atl-paas.net"

uriGroups:

  - name: Profile Router
    hidden: true
    supportedUris:
      - in: /p/{profile}/*
        out:
          - method: GET
          - method: POST
          - method: OPTIONS

  - name: OpenAI
    supportedUris:
      - in: /openai/v1/chat/completions
        description: Chat endpoint
        out:
          - method: POST
            text: /v1/openai/v1/chat/completions

      - in: /openai/v1/responses
        description: Responses endpoint
        out:
          - method: POST
            text: /v1/openai/v1/responses

      - in: /openai/v1/images/generations
        description: Image generation endpoint
        out:
          - method: POST
            text: /v1/openai/v1/images/generations

      - in: /openai/v1/models
        description: Model list endpoint
        out:
          - method: GET

  - name: Claude
    supportedUris:
      - in: /bedrock/claude/v1/messages
        description: Chat endpoint
        out:
          - method: OPTIONS
          - method: POST
            expr: |
              "/v1/bedrock/model/" + regexReplace("^(claude-.*-\\d{8})$", "anthropic.$1-v1:0", body.model) + "/invoke" + (body.stream ? "-with-response-stream" : "")

      - in: /bedrock/claude/models
        description: Model list endpoint
        out:
          - method: GET

      - in: /bedrock/claude/v1/models
        description: Model list endpoint
        out:
          - method: GET

      - in: /provider/bedrock/format/openai/v1/chat/completions
        description: OpenAI-compatible chat endpoint
        out:
          - method: OPTIONS
          - method: POST
            expr: |
              "/v1/bedrock/model/" + regexReplace("^(claude-.*-\\d{8})$", "anthropic.$1-v1:0", body.model) + "/invoke" + (body.stream ? "-with-response-stream" : "")

      - in: /provider/bedrock/format/openai/v1/models
        description: OpenAI-compatible model list endpoint
        out:
          - method: GET

      - in: /vertex/claude/v1/messages
        description: Chat endpoint
        out:
          - method: OPTIONS
          - method: POST
            expr: |
              "/v1/google/v1/publishers/anthropic/models/" + regexReplace("^(.+)-(\\d{8})$", "$1@$2", body.model) + ":" + (body.stream ? "streamRawPredict" : "rawPredict")

      - in: /vertex/claude/models
        description: Model list endpoint
        out:
          - method: GET

      - in: /vertex/claude/v1/models
        description: Model list endpoint
        out:
          - method: GET

  - name: Gemini
    supportedUris:
      - in: /google/gemini/v1beta/models/{model}:generateContent
        description: Chat endpoint
        out:
          - method: POST
            expr: |
              "/v1/google/v1/publishers/google/models/" + pathParams.model + ":generateContent"

      - in: /google/gemini/v1beta/models/{model}:streamGenerateContent
        description: Streamed chat endpoint
        out:
          - method: POST
            expr: |
              "/v1/google/v1/publishers/google/models/" + pathParams.model + ":streamGenerateContent"

overrides:
  global:
    request:
      headers:
        # If no name is define for op: remove, then it removes all headers
        - op: remove

        - op: add
          name: User-Agent
          expr: '"proximity/" + version'

        - op: add
          name: Content-Type
          text: application/json
        - op: add
          name: Accept
          text: application/json

        - op: add
          name: X-Atlassian-CloudId
          expr: |
            let profileHeader = get(headers, "X-Proximity-Profile");
            let profileName = (profileHeader != nil ? profileHeader[0] : nil) ?? get(settings, "defaultProfile") ?? settings.profiles[0].name;
            let profile = filter(settings.profiles, #.name == profileName)[0];
            get(profile, "atlassianCloudId") ?? get(settings, "atlassianCloudId") ?? "a436116f-02ce-4520-8fbb-7301462a1674"

        - op: add
          name: X-Atlassian-UseCaseId
          expr: |
            let profileHeader = get(headers, "X-Proximity-Profile");
            let profileName = (profileHeader != nil ? profileHeader[0] : nil) ?? get(settings, "defaultProfile") ?? settings.profiles[0].name;
            let profile = filter(settings.profiles, #.name == profileName)[0];
            get(profile, "useCaseId")

        - op: add
          name: Authorization
          expr: |
            let profileHeader = get(headers, "X-Proximity-Profile");
            let profileName = (profileHeader != nil ? profileHeader[0] : nil) ?? get(settings, "defaultProfile") ?? settings.profiles[0].name;
            let profile = filter(settings.profiles, #.name == profileName)[0];

            let adGroup = get(profile, "adGroup");
            let adGroupList = adGroup != nil ? [adGroup] : [];

            "slauth " + slauthtoken(adGroupList, "ai-gateway", get(settings, "aiGatewayEnv") ?? "staging")

    response:
      headers:
        - op: remove

        # Default Content-Type to be updated by individual endpoints if necessary
        - op: add
          name: Content-Type
          text: application/json

  uris:
    /p/{profile}/*:
      GET: &forwarding_config
        forward:
          path:
            expr: '"/" + pathParams["*"]'
          headers:
            - op: add
              name: X-Proximity-Profile
              expr: pathParams.profile

      POST: *forwarding_config
      OPTIONS: *forwarding_config


    /openai/v1/chat/completions:
      POST:
        request:
          body:
            expr: |
              toCompactJson(merge(filterOutKeys(body, ["max_tokens"]),
                get(body, "max_tokens") != nil ? { "max_completion_tokens": get(body, "max_tokens") } : {}
              ))

        response:
          headers:
            - op: add
              name: Content-Type
              expr: headers["Content-Type"][0]

          body:
            expr: |
              event != nil ? (
                let eventJson = trimPrefix(event ?? "", "data:") | trim();

                len(eventJson) > 0 ? ("data: " + eventJson + "\n") : "\n"
              ) : (
                toCompactJson(body)
              )


    /openai/v1/responses:
      POST:
        response:
          headers:
            - op: add
              name: Content-Type
              expr: headers["Content-Type"][0]

          body:
            expr: |
              event != nil ? (
                let eventJson = trimPrefix(event ?? "", "data:") | trim();

                len(eventJson) > 0 ? ("data: " + eventJson + "\n") : "\n"
              ) : (
                toCompactJson(body)
              )


    /openai/v1/models:
      GET:
        response:
          statusCode: 200

          body:
            expr: |
              toCompactJson({
                "object": "list",
                "data": map(external.openai, true ? {
                  "id": #,
                  "object": "model",
                  "created": timestamp(),
                  "owned_by": "atlassian"
                } : {})
              })


    # Use the Bedrock provider. All models can be accessed through the proxy
    # using the anthropic claude format.
    /bedrock/claude/v1/messages:
      OPTIONS: &claude_options_response
        response:
          statusCode: 200

          headers:
            - op: add
              name: Access-Control-Allow-Origin
              text: "*"
            - op: add
              name: Access-Control-Allow-Methods
              text: POST, OPTIONS
            - op: add
              name: Access-Control-Allow-Headers
              text: "*"
            - op: add
              name: Access-Control-Max-Age
              text: "86400"


      POST:
        request:
          headers:
            # The bedrock api requires the anthropic version in the body rather
            # than as a header like the anthropic api so the header needs to be
            # removed.
            - op: remove
              name: anthropic-version

            # No need for this when using AI-Gateway
            - op: remove
              name: x-api-key

          body:
            expr: |
              toCompactJson(merge(filterOutKeys(body, ["model", "stream", "messages"]), {
                anthropic_version: "bedrock-2023-05-31",
                messages: map(body.messages, 
                  type(#.content) == "string" 
                    ? {
                        role: #.role,
                        content: [{
                          type: "text",
                          text: safeEncode(#.content)
                        }]
                      }
                    : #
                )
              }))

        response:
          headers:
            - op: add
              name: Content-Type
              expr: headers["Content-Type"][0]
            - op: add
              name: Access-Control-Allow-Origin
              text: "*"

          body:
            expr: |
              event != nil ? (
                let eventJson = trimPrefix(event ?? "", "data:") | trim();

                len(eventJson) > 0 ? (
                  let eventObj = fromJSON(eventJson);
                  let eventLine = get(eventObj, "type") == "message_stop" ? toCompactJson({type: "message_stop"}) : eventJson;

                  "event: " + get(eventObj, "type") + "\n" + "data: " + eventLine + "\n"
                ) : "\n"
              ) : (
                toCompactJson(body)
              )


    /bedrock/claude/models: &bedrock_models_route
      GET:
        response:
          statusCode: 200

          body:
            expr: |
              toCompactJson({
                data: map(external.bedrock, true ? {
                  created_at: formattedTimestamp("2006-01-02T15:04:05Z"),
                  display_name: #,
                  id: #,
                  type: "model"
                } : {}),
                first_id: external.bedrock[0],
                has_more: false,
                last_id: external.bedrock[len(external.bedrock) - 1]
              })


    /bedrock/claude/v1/models: *bedrock_models_route


    # Use the Bedrock provider. All models can be accessed through the proxy
    # using the anthropic claude format.
    /vertex/claude/v1/messages:
      OPTIONS: *claude_options_response

      POST:
        request:
          headers:
            # The bedrock api requires the anthropic version in the body rather
            # than as a header like the anthropic api so the header needs to be
            # removed.
            - op: remove
              name: anthropic-version

            # No need for this when using AI-Gateway
            - op: remove
              name: x-api-key

          body:
            expr: |
              toCompactJson(merge(filterOutKeys(body, ["model", "stream", "messages"]), {
                anthropic_version: "vertex-2023-10-16",
                messages: map(body.messages, 
                  type(#.content) == "string" 
                    ? {
                        role: #.role,
                        content: [{
                          type: "text",
                          text: safeEncode(#.content)
                        }]
                      }
                    : #
                )
              }))

        response:
          headers:
            - op: add
              name: Content-Type
              expr: headers["Content-Type"][0]
            - op: add
              name: Access-Control-Allow-Origin
              text: "*"

          body:
            expr: |
              event != nil ? (
                let eventJson = trimPrefix(event ?? "", "data:") | trim();

                len(eventJson) > 0 ? (
                  let eventObj = fromJSON(eventJson);
                  let eventLine = get(eventObj, "type") == "message_stop" ? toCompactJson({type: "message_stop"}) : eventJson;

                  "event: " + get(eventObj, "type") + "\n" + "data: " + eventLine + "\n"
                ) : "\n"
              ) : (
                toCompactJson(body)
              )


    /vertex/claude/models: &vertex_models_route
      GET:
        response:
          statusCode: 200

          body:
            expr: |
              toCompactJson({
                data: map(external.vertex, true ? {
                  created_at: formattedTimestamp("2006-01-02T15:04:05Z"),
                  display_name: #,
                  id: #,
                  type: "model"
                } : {}),
                first_id: external.vertex[0],
                has_more: false,
                last_id: external.vertex[len(external.vertex) - 1]
              })


    /vertex/claude/v1/models: *vertex_models_route


    /provider/bedrock/format/openai/v1/chat/completions:
      OPTIONS: *claude_options_response

      POST:
        request:
          body:
            expr: |
              let base = filterOutKeys(body, ["model", "stream", "messages", "tools", "tool_choice", "max_tokens", "max_completion_tokens", "stop", "parallel_tool_calls", "reasoning_effort", "stream_options"]);
              let maxTokens = get(body, "max_tokens") ?? get(body, "max_completion_tokens") ?? 8192;
              let hasSystem = len(body.messages) > 0 && body.messages[0].role == "system";
              let systemObj = hasSystem ? { system: safeEncode(body.messages[0].content) } : {};

              let stopObj = get(body, "stop") != nil
                ? { stop_sequences: type(body.stop) == "string" ? [body.stop] : body.stop }
                : {};

              let toolsObj = get(body, "tools") != nil
                ? {
                    tools: map(filter(body.tools, true ? #.type == "function" : false), true ? {
                      name: #.function.name,
                      description: safeEncode(#.function.description ?? ""),
                      input_schema: #.function.parameters
                    } : {})
                  }
                : {};

              let toolChoiceObj = get(body, "tool_choice") != nil
                ? {
                    tool_choice: type(body.tool_choice) == "string"
                      ? (body.tool_choice == "auto" ? { type: "auto" } : { type: "any" })
                      : { type: "tool", name: body.tool_choice.function.name }
                  }
                : {};

              let nonSystemMsgs = filter(body.messages, true ? #.role != "system" : false);

              let convertedMsgs = map(nonSystemMsgs, true ? (
                #.role == "tool" ? {
                  role: "user",
                  content: [{
                    type: "tool_result",
                    tool_use_id: get(#, "tool_call_id"),
                    content: get(#, "content") ?? ""
                  }]
                } : #.role == "assistant" && get(#, "tool_calls") != nil ? {
                  role: "assistant",
                  content: map(get(#, "tool_calls") ?? [], true ? (
                    let args = get(get(#, "function") ?? {}, "arguments") ?? "";
                    {
                      type: "tool_use",
                      id: get(#, "id"),
                      name: get(get(#, "function") ?? {}, "name"),
                      input: len(args) > 0 ? fromJSON(args) : {}
                    }
                  ) : {})
                } : {
                  role: #.role,
                  content: type(#.content) == "string"
                    ? [{ type: "text", text: safeEncode(#.content) }]
                    : map(#.content, true ? (
                        #.type == "text"
                          ? { type: "text", text: safeEncode(#.text) }
                          : (#.type == "image_url" || #.type == "input_image")
                            ? {
                                type: "image",
                                source: {
                                  type: "base64",
                                  media_type: regexFind("^data:(image/[^;]+);", #.image_url.url),
                                  data: regexFind(",(.+)$", #.image_url.url)
                                }
                              }
                            : #
                      ) : {})
                }
              ) : {});

              toCompactJson(merge(
                base,
                {
                  anthropic_version: "bedrock-2023-05-31",
                  max_tokens: maxTokens,
                  messages: convertedMsgs
                },
                systemObj,
                stopObj,
                toolsObj,
                toolChoiceObj
              ))

        response:
          headers:
            - op: add
              name: Content-Type
              expr: headers["Content-Type"][0]
            - op: add
              name: Access-Control-Allow-Origin
              text: "*"

          body:
            expr: |
              event != nil ? (
                let eventJson = trimPrefix(event ?? "", "data:") | trim();

                len(eventJson) > 0 ? (
                  let e = fromJSON(eventJson);
                  let eventType = get(e, "type") ?? "";
                  let msg = get(e, "message") ?? {};
                  let msgId = get(msg, "id") ?? "";
                  let msgModel = get(msg, "model") ?? "";
                  let msgUsage = get(msg, "usage") ?? {};
                  let delta = get(e, "delta") ?? {};
                  let deltaText = get(delta, "text") ?? "";
                  let eUsage = get(e, "usage") ?? {};

                  eventType == "message_start" ? (
                    setToStorage("requestId", msgId);
                    setToStorage("model", msgModel);
                    setToStorage("input_tokens", string(get(msgUsage, "input_tokens") ?? 0));
                    setToStorage("output_tokens", string(get(msgUsage, "output_tokens") ?? 0));
                    setToStorage("tool_count", "0");
                    "data: " + toCompactJson({
                      id: msgId,
                      object: "chat.completion.chunk",
                      created: timestamp(),
                      model: msgModel,
                      service_tier: "scale",
                      system_fingerprint: nil,
                      choices: [{
                        index: 0,
                        delta: { role: "assistant" },
                        logprobs: nil,
                        finish_reason: nil
                      }],
                      usage: nil
                    }) + "\n\n"
                  ) : eventType == "content_block_start" ? (
                    let contentBlock = get(e, "content_block") ?? {};
                    let blockType = get(contentBlock, "type") ?? "";
                    let blockIndex = get(e, "index") ?? 0;

                    blockType == "tool_use" ? (
                      let currentToolCount = int(getFromStorage("tool_count") ?? "0");
                      setToStorage("tool_count", string(currentToolCount + 1));
                      setToStorage("block_to_tool_" + string(blockIndex), string(currentToolCount));
                      "data: " + toCompactJson({
                        id: getFromStorage("requestId"),
                        object: "chat.completion.chunk",
                        created: timestamp(),
                        model: getFromStorage("model"),
                        service_tier: "scale",
                        system_fingerprint: nil,
                        choices: [{
                          index: 0,
                          delta: {
                            tool_calls: [{
                              index: currentToolCount,
                              id: get(contentBlock, "id"),
                              type: "function",
                              function: {
                                name: get(contentBlock, "name"),
                                arguments: ""
                              }
                            }]
                          },
                          logprobs: nil,
                          finish_reason: nil
                        }],
                        usage: nil
                      }) + "\n\n"
                    ) : ""
                  ) : eventType == "content_block_delta" ? (
                    let deltaType = get(delta, "type") ?? "text_delta";
                    let blockIndex = get(e, "index") ?? 0;

                    deltaType == "input_json_delta" ? (
                      let toolIndex = int(getFromStorage("block_to_tool_" + string(blockIndex)) ?? "0");
                      let partialJson = get(delta, "partial_json") ?? "";
                      "data: " + toCompactJson({
                        id: getFromStorage("requestId"),
                        object: "chat.completion.chunk",
                        created: timestamp(),
                        model: getFromStorage("model"),
                        service_tier: "scale",
                        system_fingerprint: nil,
                        choices: [{
                          index: 0,
                          delta: {
                            tool_calls: [{
                              index: toolIndex,
                              function: {
                                arguments: partialJson
                              }
                            }]
                          },
                          logprobs: nil,
                          finish_reason: nil
                        }],
                        usage: nil
                      }) + "\n\n"
                    ) : (
                      "data: " + toCompactJson({
                        id: getFromStorage("requestId"),
                        object: "chat.completion.chunk",
                        created: timestamp(),
                        model: getFromStorage("model"),
                        service_tier: "scale",
                        system_fingerprint: nil,
                        choices: [{
                          index: 0,
                          delta: { content: deltaText },
                          logprobs: nil,
                          finish_reason: nil
                        }],
                        usage: nil
                      }) + "\n\n"
                    )
                  ) : eventType == "message_delta" ? (
                    let stopReason = get(delta, "stop_reason") ?? "end_turn";
                    let finishReason = stopReason == "end_turn" ? "stop"
                      : stopReason == "tool_use" ? "tool_calls"
                      : "stop";
                    setToStorage("output_tokens", string(get(eUsage, "output_tokens") ?? 0));
                    setToStorage("finish_reason", finishReason);
                    "data: " + toCompactJson({
                      id: getFromStorage("requestId"),
                      object: "chat.completion.chunk",
                      created: timestamp(),
                      model: getFromStorage("model"),
                      service_tier: "scale",
                      system_fingerprint: nil,
                      choices: [{
                        index: 0,
                        delta: {},
                        logprobs: nil,
                        finish_reason: finishReason
                      }],
                      usage: nil
                    }) + "\n\n"
                  ) : eventType == "message_stop" ? (
                    let inputTokens = int(getFromStorage("input_tokens") ?? "0");
                    let outputTokens = int(getFromStorage("output_tokens") ?? "0");
                    "data: " + toCompactJson({
                      id: getFromStorage("requestId"),
                      object: "chat.completion.chunk",
                      created: timestamp(),
                      model: getFromStorage("model"),
                      service_tier: "scale",
                      system_fingerprint: nil,
                      choices: [],
                      usage: {
                        prompt_tokens: inputTokens,
                        completion_tokens: outputTokens,
                        total_tokens: inputTokens + outputTokens,
                        prompt_tokens_details: { cached_tokens: 0, audio_tokens: 0 },
                        completion_tokens_details: {
                          reasoning_tokens: 0,
                          audio_tokens: 0,
                          accepted_prediction_tokens: 0,
                          rejected_prediction_tokens: 0
                        }
                      }
                    }) + "\n\ndata: [DONE]\n\n"
                  ) : ""
                ) : "\n"
              ) : (
                let b = body ?? {};
                let content = get(b, "content") ?? [];
                let stopReason = get(b, "stop_reason") ?? "stop";
                let finishReason = stopReason == "end_turn" ? "stop"
                  : stopReason == "tool_use" ? "tool_calls"
                  : stopReason;
                let textBlocks = filter(content, true ? get(#, "type") == "text" : false);
                let toolBlocks = filter(content, true ? get(#, "type") == "tool_use" : false);
                let hasToolUse = len(toolBlocks) > 0;
                let firstTextBlock = getIndex(textBlocks, 0);
                let textContent = firstTextBlock != nil ? (get(firstTextBlock, "text") ?? "") : "";
                let toolCalls = hasToolUse
                  ? map(toolBlocks, true ? {
                      id: get(#, "id"),
                      type: "function",
                      function: {
                        name: get(#, "name"),
                        arguments: toCompactJson(get(#, "input") ?? {})
                      }
                    } : {})
                  : nil;
                let usage = get(b, "usage") ?? {};
                let inputTokens = get(usage, "input_tokens") ?? 0;
                let outputTokens = get(usage, "output_tokens") ?? 0;
                toCompactJson({
                  id: get(b, "id"),
                  object: "chat.completion",
                  created: timestamp(),
                  model: get(b, "model"),
                  choices: [{
                    index: 0,
                    message: hasToolUse
                      ? { role: "assistant", content: textContent != "" ? textContent : nil, tool_calls: toolCalls }
                      : { role: "assistant", content: textContent },
                    logprobs: nil,
                    finish_reason: finishReason
                  }],
                  usage: {
                    prompt_tokens: inputTokens,
                    completion_tokens: outputTokens,
                    total_tokens: inputTokens + outputTokens,
                    completion_tokens_details: {
                      reasoning_tokens: 0,
                      audio_tokens: 0,
                      accepted_prediction_tokens: 0,
                      rejected_prediction_tokens: 0
                    }
                  },
                  service_tier: "default"
                })
              )

    /provider/bedrock/format/openai/v1/models:
      GET:
        response:
          statusCode: 200

          body:
            expr: |
              toCompactJson({
                "object": "list",
                "data": map(external.bedrock, true ? {
                  "id": #,
                  "object": "model",
                  "created": timestamp(),
                  "owned_by": "atlassian"
                } : {})
              })
